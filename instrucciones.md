# Proyecto Individual 1

Instrucciones a seguir para completar el proyecto individual del M1

## Contexto y Objetivos

Eres ingeniero/a en un equipo peque√±o de producto que est√° construyendo un asistente para agentes de soporte al cliente. El asistente debe devolver, para cualquier pregunta entrante, una respuesta concisa en JSON para que los sistemas downstream puedan mostrar: una respuesta, una estimaci√≥n de confianza y acciones recomendadas. El equipo tambi√©n necesita m√©tricas por consulta (tokens, latencia y costo estimado en USD) para monitorear el uso.

### **üéØObjetivos (qu√© vas a entregar y por qu√© importa):**

- Implementar un script ejecutable o un endpoint m√≠nimo que reciba una pregunta del usuario y devuelva JSON v√°lido con campos nombrados (por ejemplo: answer, confidence, actions, etc.). Esto crea un contrato estable para integraciones posteriores.
- Registrar m√©tricas por ejecuci√≥n: tokens (prompt/completion/total), latency_ms y estimated_cost_usd. Esto habilita el monitoreo de costo y performance.
- Aplicar al menos una t√©cnica expl√≠cita de prompt engineering (few-shot, chain-of-thought, o self-consistency) y documentar por qu√© se eligi√≥.
- Entregar un reporte breve (1‚Äì2 p√°ginas) que describa: arquitectura, t√©cnica de prompting, m√©tricas de ejemplo y trade-offs.
- Incluir al menos un test automatizado (por ejemplo, validaci√≥n de JSON o conteo de tokens).
- Opcional: implementar un fallback de seguridad/moderaci√≥n para entradas adversariales.

    ¬øPor qu√© esto es importante? Outputs estructurados + m√©tricas + decisiones de prompting documentadas son habilidades clave para construir sistemas de IA confiables y sirven como base para enfoques RAG (Retrieval-Augmented Generation).

---

### üì¢Consigna

Desarrolla una aplicaci√≥n de ‚ÄúMultitasking Text Utility‚Äù que reciba una pregunta del usuario y devuelva una salida en formato JSON. Utiliza la API de OpenAI aplicando al menos una t√©cnica de prompt engineering aprendida en clase. Registra y reporta al menos tres m√©tricas, como costo, tokens utilizados y latencia.

Bonus: incluye soporte para manejar prompts adversariales y as√≠ evaluar la seguridad.

---

## Entregables del proyecto y requisitos de entrega

Enviar mediante un enlace p√∫blico al repositorio en Git. Asegurarse de que el repositorio sea autocontenido y que se pueda ejecutar sin depender de elementos externos no documentados.

### üìÇEstructura de repositorio esperada

| Entregable | Archivo/Formato | Contenido m√≠nimo |
| :---: | :---: | --- |
| Aplicaci√≥n o script ejecutable | src/run_query.py or app/endpoint.py (or notebook .ipynb) | src/run_query.py or app/endpoint.py (or notebook .ipynb) |
| Plantilla(s) de prompt | prompts/main_prompt.txt (or .md) | Prompt basado en instrucciones; incluir algunos ejemplos few-shot; instrucciones de esquema JSON. |
| Registro de m√©tricas | metrics/metrics.csv or metrics/metrics.json | M√©tricas por ejecuci√≥n: timestamp, tokens_prompt, tokens_completion, total_tokens, latency_ms, estimated_cost_usd. |
| Informe breve | reports/PI_report_en.md (1‚Äì2 pages) | Informe breve: visi√≥n de arquitectura, t√©cnica(s) de prompting usada(s) y por qu√©, resumen de m√©tricas con resultados de muestra, desaf√≠os y posibles mejoras. |
| README | README.md | README: setup, variables de entorno, comandos de ejecuci√≥n, c√≥mo reproducir m√©tricas, limitaciones conocidas. |
| Tests | tests/test_core.py | tests/test_core.py |
| Manejo de seguridad (bonus) | src/safety.py + docs in report | Seguridad (bonus): paso de moderaci√≥n o fallback; ejemplo de prompt adversarial y resultado; registro (logging) de decisiones. |

## ‚úÖChecklist de entrega

- Uso de la API key documentado mediante variable de entorno (OPENAI_API_KEY). Incluir .env.example.
- Al menos una ejecuci√≥n registrada que produzca JSON y m√©tricas.
- Reporte y README completos y consistentes entre s√≠.
